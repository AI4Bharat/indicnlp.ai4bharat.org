<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pages on AI4Bharat IndicNLP</title>
    <link>http://localhost/pages/</link>
    <description>Recent content in Pages on AI4Bharat IndicNLP</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="http://localhost/pages/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>IndicCorp</title>
      <link>http://localhost/corpora/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/corpora/</guid>
      <description>IndicCorp has been developed by discovering and scraping thousands of web sources - primarily news, magazines and books, over a duration of several months.
IndicCorp is one of the largest publicly-available corpora for Indian languages. It has also been used to train our released models which have obtained state-of-the-art performance on many tasks.
Corpus Format The corpus is a single large text file containing one sentence per line. The publicly released version is randomly shuffled, untokenized and deduplicated.</description>
    </item>
    
    <item>
      <title>IndicFT</title>
      <link>http://localhost/indicft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indicft/</guid>
      <description>fastText is a subword-aware word embedding model. It is particularly well-suited for Indian languages due to their highly agglutinative morphology. We train fastText models on our IndicNLP Corpora and evaluate them on a set of tasks to measure its performance.
Our fastText models are available for 11 Indian languages: Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu.
Usage To use our fastText models, first download them. Next, install the fastText library:</description>
    </item>
    
    <item>
      <title>IndicGLUE</title>
      <link>http://localhost/indic-glue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indic-glue/</guid>
      <description>To thoroughly evaluate language models on Indian languages, we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. IndicGLUE is a natural language understanding benchmark that we propose. It consists of 6 tasks which we describe in the next section.
In addition, we also compile a list of additional evaluations which comprises of tasks based on publicly-available datasets.
Downloads    Dataset Download Link     Soham News Article Classification link   iNLTK Headline Classification link   BBC News Article Classification link   AI4Bharat Wikipedia Section Titles link   AI4Bharat Cloze-style Question Answering link   AI4Bharat Winnograd Natural Language Inference link   AI4Bharat Choice of Plausible Alternatives link   WikiAnnNER link   CVIT-MKB Cross-lingual Sentence Retrieval link   IITP Movie Reviews Sentiment link   IITP Product Reviews link   ACTSA Sentiment Classifcation link   MIDAS Discourse link   Amrita Paraphrase link (need to request)    The code to run evaluations on the above dataset is provided in the IndicBERT repo.</description>
    </item>
    
    <item>
      <title>IndicBERT</title>
      <link>http://localhost/indic-bert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indic-bert/</guid>
      <description>IndicBERT is a multilingual ALBERT model trained on large-scale corpora, covering 12 major Indian languages: Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. IndicBERT has much less parameters than other public models like mBERT and XLM-R while it still manages to give state of the art performance on several tasks.
Download Model The model can be downloaded here. Both tf checkpoints and pytorch binaries are included in the archive.</description>
    </item>
    
    <item>
      <title>Samanantar</title>
      <link>http://localhost/samanantar/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/samanantar/</guid>
      <description>Samanantar is the largest publicly available parallel corpora collection for Indic languages: Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. The corpus has 49.6M sentence pairs between English to Indian Languages.
Update 06-07-2021 v0.2.1 data with metadata of source and Labse Alignment Score (LAS) is now available here
Update 09-06-2021 The Semantic Textual Similarity (STS) benchmark is now available for download
Update 05-06-2021 The benchmarking testsets are now available for download</description>
    </item>
    
    <item>
      <title>IndicBART</title>
      <link>http://localhost/indic-bart/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indic-bart/</guid>
      <description>Coming soon
IndicBART is a multilingual, sequence-to-sequence pre-trained model focusing on Indic languages and English. It currently supports 11 Indian languages and is based on the mBART architecture. You can use IndicBART model to build natural language generation applications for Indian languages by finetuning the model with supervised training data for tasks like machine translation, summarization, question generation, etc. Some salient features of the IndicBART are:
 Supported languages: Assamese, Bengali, Gujarati, Hindi, Marathi, Odiya, Punjabi, Kannada, Malayalam, Tamil, Telugu and English.</description>
    </item>
    
    <item>
      <title>IndicTrans</title>
      <link>http://localhost/indic-trans/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indic-trans/</guid>
      <description>-- IndicTrans is a Transformer-4X model trained on samanantar dataset. Two models are available which can translate from Indic to English and English to Indic. The model can perform translations for 11 lanaguages: Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu.
Update 05-06-2021 The Indic-Indic model is now available for download
Update 30-04-2021 The models are now available for download
Download Model  Indic-English model can be downloaded from here English-Indic model can be downloaded from here Indic-Indic can be downloaded from here  Usage The instructions for running inference can be found at IndicTrans GitHub repository</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>http://localhost/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/publications/</guid>
      <description>Gowtham Ramesh, Sumanth Doddapaneni, Aravinth Bheemaraj, Mayank Jobanputra, Raghavan AK, Ajitesh Sharma, Sujit Sahoo, Harshita Diddee, Mahalakshmi J, Divyanshu Kakwani, Navneet Kumar, Aswin Pradeep, Kumar Deepak, Vivek Raghavan, Anoop Kunchukuttan, Pratyush Kumar, Mitesh Shantadevi Khapra. Samanantar: The Largest Publicly Available Parallel Corpora Collection for 11 Indic Languages. arXiv preprint arXiv:2104.05596. pdf Divyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, Gokul N.C., Avik Bhattacharyya, Mitesh M. Khapra, Pratyush Kumar. 2020. IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages.</description>
    </item>
    
    <item>
      <title>About Us</title>
      <link>http://localhost/aboutus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/aboutus/</guid>
      <description>Our group focuses on building NLP ecosystem for Indian languages and seeking new models and techniques better suited for Indian languages. Our project has volunteers from IIT Madras, One Fourth Labs, Microsoft Search Technology Center India.
Members       
Contact Us For any queries, feel free to reach us at:
 Anoop Kunchukuttan (anoop.kunchukuttan@gmail.com) Mitesh Khapra (miteshk@cse.iitm.ac.in) Pratyush Kumar (pratyush@cse.iitm.ac.in) Divyanshu Kakwani (divkakwani@gmail.com)  </description>
    </item>
    
    <item>
      <title>IndicNLP</title>
      <link>http://localhost/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/home/</guid>
      <description>We are working towards building a better ecosystem for Indian languages while also keeping up with the recent advancements in NLP. To this end, we are releasing IndicNLPSuite, which is a collection of various resources and models for Indian languages:
 IndicCorp: A lot of NLP models require a large amount of training data, which most of the Indian languages lack. In this project, we develop a large-scale Indic corpora by intesively crawling the web.</description>
    </item>
    
  </channel>
</rss>
