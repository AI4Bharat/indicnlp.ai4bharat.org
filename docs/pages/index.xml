<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Pages on AI4Bharat IndicNLP</title>
    <link>http://localhost/pages/</link>
    <description>Recent content in Pages on AI4Bharat IndicNLP</description>
    <generator>Hugo -- gohugo.io</generator><atom:link href="http://localhost/pages/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>IndicCorp</title>
      <link>http://localhost/corpora/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/corpora/</guid>
      <description>IndicNLP corpora has been developed by discovering and scraping thousands of web sources - primarily news, magazines and books, over a duration of several months. It has been used to train our released models.
Download Links Note 1: Stats are shown for the original file and the file obtained after deduplicating sentences.
Note 2: Links to be provided soon.
   Language # News Articles* Sentences Tokens Link     as 0.</description>
    </item>
    
    <item>
      <title>IndicFT</title>
      <link>http://localhost/indicft/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indicft/</guid>
      <description>fastText is a subword-aware word embedding model. It is particularly well-suited for Indian languages due to their highly agglutinative morphology. We train fastText models on our IndicNLP Corpora and evaluate them on a set of tasks to measure its performance.
Our fastText models are available for 11 Indian languages: Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu.
Usage To use our fastText models, first download them. Next, install the fastText library:</description>
    </item>
    
    <item>
      <title>IndicGLUE</title>
      <link>http://localhost/indic-glue/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indic-glue/</guid>
      <description>To thoroughly evaluate language models on Indian languages, we need a robust NLU benchmark consisting of a wide variety of tasks and covering all the Indian languages. IndicGLUE is a natural language understanding benchmark that we propose. It consists of 6 tasks which we describe in the next section.
In addition, we also compile a list of additional evaluations which comprises of challenging public tasks, but cover only some of the Indian languages.</description>
    </item>
    
    <item>
      <title>IndicBERT</title>
      <link>http://localhost/indic-bert/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/indic-bert/</guid>
      <description>IndicBERT is a multilingual ALBERT model trained on large-scale corpora, covering 12 major Indian languages: Assamese, Bengali, English, Gujarati, Hindi, Kannada, Malayalam, Marathi, Oriya, Punjabi, Tamil, Telugu. IndicBERT has much less parameters than other public models like mBERT and XLM-R while it still manages to give state of the art of performance on several tasks.
Download Model The model can be downloaded here. Both tf checkpoints and pytorch binaries are included in the archive.</description>
    </item>
    
    <item>
      <title>Publications</title>
      <link>http://localhost/publications/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/publications/</guid>
      <description> Divyanshu Kakwani, Anoop Kunchukuttan, Satish Golla, Gokul N.C., Avik Bhattacharyya, Mitesh M. Khapra, Pratyush Kumar. 2020. IndicNLPSuite: Monolingual Corpora, Evaluation Benchmarks and Pre-trained Multilingual Language Models for Indian Languages. Findings of EMNLP. pdf Anoop Kunchukuttan, Divyanshu Kakwani, Satish Golla, Gokul N.C., Avik Bhattacharyya, Mitesh M. Khapra, Pratyush Kumar.. 2020. AI4Bharat-IndicNLP Corpus: Monolingual Corpora and Word Embeddings for Indic Languages. arXiv preprint arXiv:2005.00085. pdf  </description>
    </item>
    
    <item>
      <title>About Us</title>
      <link>http://localhost/aboutus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/aboutus/</guid>
      <description>Our group focuses on building NLP ecosystem for Indian languages and seeking new models and techniques better suited for Indian languages. Our project has volunteers from IIT Madras, One Fourth Labs, Microsoft Search Technology Center India.
Members       
Contact Us For any queries, feel free to reach us at:
 Anoop Kunchukuttan (anoop.kunchukuttan@gmail.com) Mitesh Khapra (miteshk@cse.iitm.ac.in) Pratyush Kumar (pratyush@cse.iitm.ac.in) Divyanshu Kakwani (divkakwani@gmail.com)  </description>
    </item>
    
    <item>
      <title>IndicNLP</title>
      <link>http://localhost/home/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>http://localhost/home/</guid>
      <description>Our work is focused on building a better ecosystem for Indian languages while also keeping up with the recent advancements in NLP. To this end, we are releasing IndicNLPSuite, which is a collection of various resources and models for Indian languages:
 IndicCorp: A lot of NLP models require a large amount of training data, which most of the Indian languages lack. In this project, we develop a large-scale Indic corpora by intesively crawling the web.</description>
    </item>
    
  </channel>
</rss>
